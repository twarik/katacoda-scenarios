In this scenario, you will learn how to serve a Machine Learning Model with TensorFlow (TF) Serving using Kubeflow.

TF Serving is the recommended way to serve TensorFlow models. TF Serving enables users to quickly deploy models to production environments. We will use the interactive environment to create a single-node Kubernetes cluster allowing you to experience Kubeflow and understand how to deploy models on a  model server with gRPC/REST endpoints.
